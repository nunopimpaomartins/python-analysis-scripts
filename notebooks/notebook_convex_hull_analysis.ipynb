{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "run the following cell to import necessary packages to run the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from concave_hull import concave_hull_indexes\n",
    "from bresenham import bresenham\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from skimage.measure import label, regionprops\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askdirectory\n",
    "from tqdm import tqdm\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "import stackview\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "change the variables to the correct values.\n",
    "Set the right image size (`x` and `y` size) and the correct pixel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width, image_height = 300, 300\n",
    "pixel_size = 0.102"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this cell defines a needed function for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bresenham_points(data):\n",
    "    data_connected = data.copy()\n",
    "    data_connected = np.concatenate((data_connected, np.expand_dims(data_connected[0], axis=0)), axis=0) # add first point to close region\n",
    "    roi = data.copy()\n",
    "    for i in range(data_connected.shape[0] - 1):\n",
    "        point1 = data_connected[i]\n",
    "        point2 = data_connected[i + 1]\n",
    "        bres_line2d = bresenham(point1[1], point1[0], point2[1], point2[0])\n",
    "        intermediate_pixels = list(bres_line2d)\n",
    "        intermediate_pixels_array = np.array(intermediate_pixels[1:-1]) # excluding first and last coords which are returned in the module\n",
    "        intermediate_pixels_array = np.flip(intermediate_pixels_array, axis=1)\n",
    "        roi = np.concatenate((roi, intermediate_pixels_array), axis=0)\n",
    "\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of the analsysis\n",
    "run the first cell to tell the script where the data is.\n",
    "This needs to be done per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder path containing tables:  /mnt/Data/Data/Image Analysis/Ines_Milagre_Catolica/MAX_LT_20240829_CTRL_F01-1\n",
      "Number of tables in folder:  36\n"
     ]
    }
   ],
   "source": [
    "Tk().withdraw()\n",
    "table_directory_path = askdirectory()\n",
    "table_directory_path = Path(table_directory_path)\n",
    "print(\"Folder path containing tables: \", table_directory_path)\n",
    "\n",
    "temp_folder_path = os.path.join(table_directory_path, 'temp_images/')\n",
    "if not os.path.exists(temp_folder_path):\n",
    "    os.mkdir(temp_folder_path)\n",
    "\n",
    "table_list = os.listdir(table_directory_path)\n",
    "table_list = [x for x in table_list if x.find('.csv') > 0]\n",
    "table_list.sort()\n",
    "print('Number of tables in folder: ', str(len(table_list)))\n",
    "\n",
    "parent_folder = table_directory_path.parent\n",
    "folder_name = table_directory_path.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tosave = [[None, None, None]] * len(table_list)\n",
    "counter = 0 # should match the timepoint\n",
    "result_images = np.zeros((len(table_list), image_height, image_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table name:  MAX_LT_20240829_CTRL_F01-1_01.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_02.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_03.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_04.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_05.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_06.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_07.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_08.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_09.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_10.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_11.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_12.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_13.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_14.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_15.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_16.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_17.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_18.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_19.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_21.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_22.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_23.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_24.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_25.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_26.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_27.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_28.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_29.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_30.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_31.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_32.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_33.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_34.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_35.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_36.csv\n",
      "Table name:  MAX_LT_20240829_CTRL_F01-1_37.csv\n"
     ]
    }
   ],
   "source": [
    "for table_name in table_list:\n",
    "    print('Table name: ', table_name)\n",
    "    \n",
    "    table_data = []\n",
    "    with open(os.path.join(table_directory_path, table_name)) as f:\n",
    "        table_temp = f.read()\n",
    "        table_temp = table_temp.split('\\n')\n",
    "        table_temp = table_temp[1:-1]\n",
    "        table_temp = [x.split(',') for x in table_temp]\n",
    "        table_temp = [x[1:] for x in table_temp]\n",
    "        table_temp = [[int(x[0]), int(x[1])] for x in table_temp]\n",
    "        table_data.append(table_temp)\n",
    "    \n",
    "    table_data = np.asarray(table_data).squeeze()\n",
    "    \n",
    "    blank_image = np.zeros((image_height, image_width))\n",
    "    hull_shape_indexes = concave_hull_indexes(\n",
    "        points=table_data,\n",
    "        concavity=2.0, \n",
    "        length_threshold=0.0\n",
    "        )\n",
    "    \n",
    "    table_data_vertices = table_data[hull_shape_indexes]\n",
    "    shape_roi_coordinates = get_bresenham_points(table_data_vertices) \n",
    "    \n",
    "    for coord in shape_roi_coordinates:\n",
    "        blank_image[coord[1], coord[0]] = 1\n",
    "    \n",
    "    blank_image = binary_fill_holes(blank_image)\n",
    "    blank_image = blank_image.astype(np.uint8)\n",
    "    result_images[counter] = blank_image\n",
    "    \n",
    "    image_label = label(blank_image)\n",
    "    stats = regionprops(image_label)\n",
    "\n",
    "    area = stats[0].area\n",
    "    area_scaled = area * pixel_size**2\n",
    "\n",
    "    tifffile.imwrite(os.path.join(temp_folder_path, table_name[:table_name.index('.csv')]+'.tif'), blank_image, dtype='uint8')\n",
    "\n",
    "    data_tosave[counter] = [counter, table_name, area_scaled]\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "with open(os.path.join(parent_folder, folder_name +'_concave_hull_area.csv'), 'w') as outfile:\n",
    "    for outline in data_tosave:\n",
    "        outfile.write(str(outline[0])+','+str(outline[1])+','+str(outline[2])+'\\n')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this cell to see all the masks created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3116530b66545aaa93e035e91839c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=300, width=300),â€¦"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackview.slice(result_images, continuous_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
